{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_1.2B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_1.2B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing Sparsity and creating plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening weights for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "encoder = \"model.encoder.layers.\"\n",
    "decoder = \"model.decoder.layers.\"\n",
    "\n",
    "d = {}\n",
    "for i in range(24):\n",
    "  encoder_check = encoder+'{}.'.format(i)\n",
    "  decoder_check = decoder+'{}.'.format(i)\n",
    "  d[encoder_check] = []\n",
    "  d[decoder_check] = []\n",
    "\n",
    "KEYS = list(d.keys())\n",
    "for name, param in model.named_parameters():\n",
    "  a = (torch.flatten(param)).tolist()\n",
    "  match_list = map(name.startswith, KEYS)\n",
    "  for ind, elem in enumerate(match_list):\n",
    "    if elem:\n",
    "      match = KEYS[ind]\n",
    "      a = (torch.flatten(param)).tolist()\n",
    "      d[match].extend(a)\n",
    "      break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i = 0\n",
    "for key, val in d.items():\n",
    "    a = val\n",
    "    to_plot_dict = {}\n",
    "    to_plot_dict['-0.08'] = 0\n",
    "    to_plot_dict['-0.065'] = 0\n",
    "    to_plot_dict['-0.03'] = 0\n",
    "    to_plot_dict['0'] = 0\n",
    "    to_plot_dict['0.03'] = 0\n",
    "    to_plot_dict['0.065'] = 0\n",
    "    to_plot_dict['0.08'] = 0\n",
    "\n",
    "    for elem in a:\n",
    "        if elem <= -.08:\n",
    "            to_plot_dict['-0.08'] += 1\n",
    "        elif elem <= -.05 and elem > -.08:\n",
    "            to_plot_dict['-0.065'] += 1\n",
    "        elif elem <= -.01 and elem > -0.05:\n",
    "            to_plot_dict['-0.03'] += 1\n",
    "        elif elem <= .01 and elem > -0.01:\n",
    "            to_plot_dict['0'] += 1\n",
    "        elif elem <= .05 and elem > 0.01:\n",
    "            to_plot_dict['0.03'] += 1\n",
    "        elif elem <= .08 and elem > 0.05:\n",
    "            to_plot_dict['0.065'] += 1\n",
    "        elif elem >= 0.08:\n",
    "            to_plot_dict['0.08'] += 1\n",
    "\n",
    "    x = list(to_plot_dict.keys())\n",
    "    counts = list(to_plot_dict.values())\n",
    "    y = [ind/len(a) for ind in counts]\n",
    "    plt.figure()\n",
    "    plt.bar(x, y, color ='maroon',\n",
    "            width = 0.1)\n",
    "    plt.xlabel(\"avg value of weight\")\n",
    "    plt.ylabel(\"percentage\")\n",
    "    plt.title(\"Distribution of weights in layer {}\".format(key))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "for key, val in d.items():\n",
    "    plt.figure()\n",
    "    plt.hist(val, density = True, bins = 1000, range= (-.25, .25))\n",
    "    plt.gca().set(title='Frequency Histogram for {}'.format(key), ylabel='Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to access layers to prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.l1_unstructured.html#torch.nn.utils.prune.l1_unstructured\n",
    "def prune_layers(ratio):\n",
    "    for i in range(24):\n",
    "        list_encoder = ['model.encoder.layers.{}.self_attn.k_proj'.format(i),\n",
    "                        'model.encoder.layers.{}.self_attn.v_proj'.format(i),\n",
    "                        'model.encoder.layers.{}.self_attn.q_proj'.format(i),\n",
    "                        'model.encoder.layers.{}.self_attn.out_proj'.format(i),\n",
    "                        'model.encoder.layers.{}.self_attn_layer_norm'.format(i),\n",
    "                        'model.encoder.layers.{}.fc1'.format(i),\n",
    "                        'model.encoder.layers.{}.fc2'.format(i),\n",
    "                        'model.encoder.layers.{}.final_layer_norm'.format(i)]\n",
    "        \n",
    "        list_decoder = ['model.decoder.layers.{}.self_attn.k_proj'.format(i),\n",
    "                        'model.decoder.layers.{}.self_attn.v_proj'.format(i),\n",
    "                        'model.decoder.layers.{}.self_attn.q_proj'.format(i),\n",
    "                        'model.decoder.layers.{}.self_attn.out_proj'.format(i),\n",
    "                        'model.decoder.layers.{}.self_attn_layer_norm'.format(i),\n",
    "                        'model.decoder.layers.{}.fc1'.format(i),\n",
    "                        'model.decoder.layers.{}.fc2'.format(i),\n",
    "                        'model.decoder.layers.{}.final_layer_norm'.format(i)]\n",
    "\n",
    "        for name, module in model.named_modules():\n",
    "            if name in list_decoder or name in list_encoder:\n",
    "                prune.l1_unstructured(module, name='weight', amount=ratio)\n",
    "                prune.remove(module, 'weight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_1.2B\")\n",
    "ratio = 0.2\n",
    "prune_layers(ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
